For Feature 1 (Generating diverse synthetic dataset for training the small language model to analyze the chemical process and generate PFDs and PIDs):

"The prior art (Ai et al.) focuses on fine-tuning an LLM to extract existing chemical reaction information from unstructured text into a single, specific structured format (ORD schema). Their dataset, while large, serves this singular purpose of information extraction for known reactions.

Our invention is fundamentally different in scope and purpose:

Dataset Diversity for Comprehensive Skill Development: We generate a suite of six distinct synthetic dataset types (Factual QA, DPO, SynDIP, LogiCore, Local RAIT, Global RAIT). Each dataset is specifically designed to instill a different, complementary capability in the SLM – from foundational knowledge and preference alignment to complex reasoning and context-grounded generation, all geared towards PFD/PID tasks. Ai et al. do not disclose such a diverse, multi-faceted dataset generation strategy.

Purpose of Generation, Not Just Extraction: Our pipeline generates instructional data to train SLMs for the complex engineering task of analyzing chemical processes and generating novel PFDs and PIDs. Ai et al. are concerned with extracting and structuring data about past, documented reactions, not with generating schematics for potentially new processes.

Automated Pipeline for Specific Engineering Outputs: Our method describes an automated pipeline for generating, validating (using multi-metric reward models), and organizing these diverse datasets specifically for PFD/PID interpretation and generation, a task far more complex than single reaction data extraction."

For Feature 2 (Extracting multiple contexts from domain in the form of QA dataset, logical and multi-scale response generation, PID and PFD generation for chemical industry):

"Ai et al. extract specific, predefined fields for single organic reactions (reactants, products, conditions, workup steps) to populate the ORD schema. Their evaluation focuses on the exact-match accuracy of these extracted fields.

Our invention differs significantly in the nature and application of 'context' and the target output:

Hierarchical & Contextual Dataset Generation (SynDIP as a Core): A key inventive step in our work is the use of the SynDIP dataset (comprising structured process context, PFD textual descriptions, and PID textual descriptions) as a foundational document. The LogiCore (multi-step reasoning) and RAIT (retrieval-augmented, multi-scale response generation) datasets are then derived from or utilize SynDIP content as their primary context. This creates a hierarchical and dependency-aware data generation strategy not present in Ai et al. Ai et al. do not use one generated dataset type as the contextual basis for creating others.

Broader Scope of 'Context' for Engineering Design: Our 'contexts' are not just discrete reaction parameters. We generate:

QA datasets (Factual QA) for broad domain understanding.

LogiCore datasets for multi-step logical reasoning about process design and control logic embedded within PFD/PID descriptions (derived from SynDIP).

RAIT datasets for generating context-grounded responses (including multi-scale: brief factual and detailed explanatory) by retrieving from and synthesizing information within and across PFD/PID relevant documents (again, leveraging SynDIP-like structures).

Target Output – PFD/PID Generation: The ultimate goal of our diverse dataset generation pipeline is to enable SLMs to generate complete PFD and PID schematics for the chemical industry. This is a generative design task, far beyond the information extraction task for individual reactions described by Ai et al. Their work does not aim to generate PFDs or PIDs, nor does it describe datasets (like SynDIP, LogiCore, or RAIT built upon SynDIP) tailored for this comprehensive engineering output."
